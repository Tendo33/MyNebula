# ============================================================
# MyNebula Docker Compose 部署配置
# 使用方法: cp .env.example .env && 编辑 .env 填写必填项
# ============================================================

# ==================== 必填项 (Must Configure) ====================

# GitHub Personal Access Token
# 创建地址: https://github.com/settings/tokens
# 需要权限: public_repo, read:user
GITHUB_TOKEN=your_github_personal_access_token

# ==================== 数据库配置 ====================
# 修改密码以提升安全性，用户名和库名一般保持默认即可
DATABASE_USER=mynebula
DATABASE_PASSWORD=mynebula_secret
DATABASE_NAME=mynebula

# ==================== 可选配置 (Optional) ====================

# 宿主机映射端口 (访问地址 http://localhost:端口号)
API_PORT=8000

# 调试模式 (生产环境请设为 false)
DEBUG=false

# ==================== 管理员访问控制 ====================
# 仅管理员可访问 /settings 并执行同步、聚类、全量刷新等写操作
ADMIN_USERNAME=admin
ADMIN_PASSWORD=change_me

# 日志级别: TRACE / DEBUG / INFO / WARNING / ERROR / CRITICAL
LOG_LEVEL=INFO

# ==================== Embedding 服务配置 ====================
# 默认使用 SiliconFlow，也支持 OpenAI / Jina / Ollama 等 OpenAI 兼容接口
# Embedding 服务 API Key (用于向量化计算)
EMBEDDING_API_KEY=your_embedding_api_key
EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1
EMBEDDING_MODEL=BAAI/bge-large-zh-v1.5
EMBEDDING_DIMENSIONS=1024

# ==================== LLM 服务配置 ====================
# LLM 服务 API Key (用于生成摘要和聚类名称，推荐设置)
LLM_API_KEY=your_llm_api_key
LLM_BASE_URL=https://api.siliconflow.cn/v1
LLM_MODEL=Qwen/Qwen2.5-7B-Instruct

# ==================== 同步配置 ====================
# Star 同步批次大小
SYNC_BATCH_SIZE=100
# README 最大抓取长度 (字符)
README_MAX_LENGTH=10000
